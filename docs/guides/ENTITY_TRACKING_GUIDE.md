# Entity Tracking & Migration Management Guide

## ğŸ¯ Overview

The **Entity Tracking System** provides complete visibility and control over your Glue â†’ Databricks migration:

- **ğŸ“Š Track every entity** (modules, classes, functions) from both codebases
- **ğŸ” SQLite database** for fast queries and reporting
- **ğŸ“ˆ Streamlit dashboard** for beautiful visualization
- **ğŸ¤– Optional AI validation** for quality assurance
- **âš™ï¸ YAML configuration** for easy management

---

## ğŸ“ Files Overview

```
glue2lakehouse/
â”œâ”€â”€ migration_config.yaml          # Main configuration file
â”œâ”€â”€ migration_manager.py            # CLI tool (main entry point)
â”œâ”€â”€ migration_dashboard.py          # Streamlit dashboard
â”œâ”€â”€ migration_entities.db           # SQLite database (auto-generated)
â”œâ”€â”€ glue2lakehouse/
â”‚   â”œâ”€â”€ entity_tracker.py          # Entity tracking system
â”‚   â”œâ”€â”€ dual_track.py              # Dual-track sync manager
â”‚   â””â”€â”€ sdk.py                     # Python SDK
```

---

## ğŸš€ Quick Start

### Step 1: Configure Your Migration

Edit `migration_config.yaml`:

```yaml
# Project info
project:
  name: "Risk Engine Migration"
  owner: "Analytics360"

# Source (Glue)
source:
  path: "/path/to/glue_risk_engine"
  git_url: "https://github.com/company/glue-risk-engine.git"
  scan_paths:
    - "src/"
    - "jobs/"
    - "utils/"

# Target (Databricks)
target:
  path: "/path/to/databricks_risk_engine"
  git_url: "https://github.com/company/databricks-risk-engine.git"
  scan_paths:
    - "src/"
    - "jobs/"

# Migration settings
migration:
  catalog_name: "production"
  mode: "dual_track"

# Entity tracking
entity_tracking:
  enabled: true
  database_path: "migration_entities.db"
```

### Step 2: Scan Repositories

```bash
python migration_manager.py --config migration_config.yaml --scan
```

**Output:**
```
ğŸ“‚ Scanning Glue repository...
   Found 45 Python files
   Extracted 312 entities (78 modules, 52 classes, 182 functions)

ğŸ“‚ Scanning Databricks repository...
   Found 8 Python files
   Extracted 45 entities (12 modules, 8 classes, 25 functions)

ğŸ“Š Scan Summary:
   Total entities: 357
   Glue entities: 312
   Databricks entities: 45
```

### Step 3: Run Initial Migration

```bash
python migration_manager.py --config migration_config.yaml --migrate
```

**Output:**
```
âœ… Migration successful!
   Files migrated: 45
   
ğŸ“Š Updating entity database...
   Marked 312 entities as migrated
   
âœ… Initial migration complete!
```

### Step 4: Launch Dashboard

```bash
python migration_manager.py --config migration_config.yaml --dashboard
```

Your browser opens at `http://localhost:8501` with the **Migration Dashboard**.

---

## ğŸ“Š Entity Database Schema

The SQLite database tracks everything:

### Entities Table

| Column | Type | Description |
|--------|------|-------------|
| `entity_id` | TEXT | Unique hash identifier |
| `entity_type` | TEXT | module/class/function/method |
| `name` | TEXT | Entity name |
| `full_path` | TEXT | e.g., `src.utils.s3.write_to_table` |
| `source_type` | TEXT | `glue` or `databricks` |
| `file_path` | TEXT | Absolute file path |
| `module_name` | TEXT | Python module path |
| `line_start` | INT | Starting line number |
| `line_end` | INT | Ending line number |
| `definition` | TEXT | Function signature or class definition |
| `docstring` | TEXT | Documentation string |
| `complexity` | INT | Cyclomatic complexity score |
| `lines_of_code` | INT | Total lines of code |
| `git_commit` | TEXT | Last Git commit hash |
| `git_author` | TEXT | Last Git author |
| `created_date` | TEXT | ISO timestamp |
| `updated_date` | TEXT | ISO timestamp |
| `migration_status` | TEXT | pending/migrated/skipped/databricks_native |
| `needs_sync` | INT | 1 if needs sync from Glue |
| `is_databricks_native` | INT | 1 if Databricks-specific |
| `has_conflicts` | INT | 1 if conflicts detected |
| `imports` | TEXT | Comma-separated imports |
| `calls_functions` | TEXT | Comma-separated function calls |
| `notes` | TEXT | Custom notes |
| `tags` | TEXT | Comma-separated tags |

### Migration History Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | INT | Auto-increment ID |
| `entity_id` | TEXT | Foreign key to entities |
| `action` | TEXT | Action performed |
| `timestamp` | TEXT | ISO timestamp |
| `details` | TEXT | Additional details |

---

## ğŸ¨ Streamlit Dashboard

### Overview Page
- **Key Metrics**: Total entities, migration progress, conflicts
- **Charts**: Entity type distribution, migration status
- **Recent Updates**: Latest entity changes

### Entities Browser
- **Filters**: Source type, entity type, migration status
- **Table View**: All entities with key metadata
- **Export**: Download as CSV

### Dual-Track Sync
- **Status**: Last sync, protected files, sync history
- **Actions**: Preview sync, apply sync, check status
- **Protected Files**: List of Databricks-native files

### Analytics
- **Complexity Analysis**: Distribution charts
- **Top Complex Entities**: Most complex code
- **Migration Progress**: Timeline and metrics

### Settings
- **Repository Scanning**: Scan Glue/Databricks repos
- **Database Management**: Reset, export, stats

---

## ğŸ”„ Weekly Workflow Example

### Monday Morning: Sync Glue Changes

```bash
# 1. Preview changes
python migration_manager.py --config migration_config.yaml --sync --dry-run
```

**Output:**
```
ğŸ“Š Sync Preview:
   Files to sync: 3
     â€¢ src/readers/s3_reader.py (Glue changed)
     â€¢ src/jobs/process_b.py (Glue changed)
     â€¢ src/ddl/customers.sql (new file)
   Files protected: 1
     â€¢ src/jobs/process_d.py (Databricks-native)
   Conflicts: 0
```

```bash
# 2. Apply sync
python migration_manager.py --config migration_config.yaml --sync
```

**Output:**
```
âœ… Sync complete!
   Files synced: 3
   Files protected: 1
   Conflicts: 0
   
ğŸ“Š Entity database updated
```

```bash
# 3. View dashboard
python migration_manager.py --config migration_config.yaml --dashboard
```

---

## ğŸ¤– AI Validation (Optional)

Enable AI validation in `migration_config.yaml`:

```yaml
ai_validation:
  enabled: true
  provider: "openai"
  
  openai:
    api_key_env: "OPENAI_API_KEY"
    model: "gpt-4"
  
  checks:
    - "logic_equivalence"
    - "performance_regression"
    - "data_quality"
    - "error_handling"
```

Then validate entities:

```bash
# Get entity ID from dashboard or database
python migration_manager.py --config migration_config.yaml --validate abc123def456
```

**Output:**
```json
{
  "entity_id": "abc123def456",
  "entity_name": "process_risk_scores",
  "checks": {
    "logic_equivalence": "passed",
    "performance": "warning",
    "data_quality": "passed",
    "error_handling": "passed"
  },
  "recommendations": [
    "Consider caching intermediate DataFrames",
    "Add partition pruning for better performance"
  ]
}
```

---

## ğŸ“Š Example Use Cases

### Use Case 1: Track What Needs Migration

```python
from glue2lakehouse.entity_tracker import EntityTracker

tracker = EntityTracker("migration_entities.db")

# Get all pending entities
pending = tracker.get_entities(
    source_type="glue",
    migration_status="pending"
)

print(f"ğŸ“‹ {len(pending)} entities need migration:")
for entity in pending:
    print(f"   â€¢ {entity['full_path']} ({entity['entity_type']})")
```

### Use Case 2: Identify Databricks-Native Code

```python
# Get Databricks-specific entities
databricks_native = tracker.get_entities(
    source_type="databricks",
    migration_status="databricks_native"
)

print(f"ğŸ”’ {len(databricks_native)} protected entities:")
for entity in databricks_native:
    print(f"   â€¢ {entity['full_path']}")
```

### Use Case 3: Generate Migration Report

```python
stats = tracker.get_migration_stats()

print("ğŸ“Š Migration Report:")
print(f"   Total entities: {stats['overall']['total_entities']}")
print(f"   Migrated: {stats['overall']['migrated']}")
print(f"   Pending: {stats['overall']['pending']}")
print(f"   Progress: {stats['overall']['migrated'] / stats['overall']['source_entities'] * 100:.1f}%")
```

### Use Case 4: Find Complex Code

```python
# Get most complex entities
complex_entities = tracker.get_entities()
sorted_by_complexity = sorted(
    complex_entities,
    key=lambda x: x['complexity'],
    reverse=True
)[:10]

print("ğŸ”¥ Top 10 Most Complex Entities:")
for entity in sorted_by_complexity:
    print(f"   â€¢ {entity['name']}: complexity={entity['complexity']}, LOC={entity['lines_of_code']}")
```

---

## ğŸ¯ Complete Workflow for Your Risk Engine

### Initial Setup (One-Time)

```bash
# 1. Configure
vim migration_config.yaml
# Update source and target paths

# 2. Scan both repositories
python migration_manager.py --config migration_config.yaml --scan

# 3. Review in dashboard
python migration_manager.py --config migration_config.yaml --dashboard

# 4. Run initial migration
python migration_manager.py --config migration_config.yaml --migrate

# 5. Mark Databricks-native code
# (Do this in dashboard or via Python API)
```

### Weekly Sync (Recurring)

```bash
# Every Monday morning:

# 1. Check status
python migration_manager.py --config migration_config.yaml --status

# 2. Preview sync
python migration_manager.py --config migration_config.yaml --sync --dry-run

# 3. Review in dashboard
python migration_manager.py --config migration_config.yaml --dashboard

# 4. Apply sync
python migration_manager.py --config migration_config.yaml --sync

# 5. Verify
python migration_manager.py --config migration_config.yaml --status
```

### Automated Sync (Cron Job)

Add to crontab:

```bash
# Every Monday at 9 AM
0 9 * * 1 cd /path/to/glue2lakehouse && python migration_manager.py --config migration_config.yaml --sync >> sync.log 2>&1
```

---

## ğŸ“ˆ Dashboard Screenshots (Conceptual)

### Overview Page
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š Migration Overview                                      â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Total    â”‚  â”‚ Migrated â”‚  â”‚ Databricksâ”‚  â”‚ Conflictsâ”‚  â”‚
â”‚  â”‚ Entities â”‚  â”‚ 245/312  â”‚  â”‚ Native    â”‚  â”‚ 0        â”‚  â”‚
â”‚  â”‚ 357      â”‚  â”‚ 78.5%    â”‚  â”‚ 45        â”‚  â”‚          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 78.5%                    â”‚
â”‚                                                             â”‚
â”‚  ğŸ“Š Entity Types          ğŸ“ˆ Migration Status               â”‚
â”‚  [Pie Chart]             [Bar Chart]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Entities Browser
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“ Entity Browser                                          â”‚
â”‚                                                             â”‚
â”‚  Filters: [Glue â–¼] [Function â–¼] [Migrated â–¼]              â”‚
â”‚                                                             â”‚
â”‚  Name             | Type    | Module        | LOC | Status â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  write_to_table   | function| utils.s3      | 150 |âœ…Migr. â”‚
â”‚  read_from_s3     | function| readers.s3    | 85  |âœ…Migr. â”‚
â”‚  process_risk     | function| jobs.process  | 320 |â³Pend. â”‚
â”‚  ...                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Benefits of Entity Tracking

### For Your Risk Engine Migration

âœ… **Complete Visibility**
- Know exactly what's migrated vs pending
- Track every function, class, module
- See complexity and LOC for each entity

âœ… **Safe Dual-Track Development**
- Identify Databricks-native code instantly
- Never overwrite protected code
- Clear conflict detection

âœ… **Progress Tracking**
- Real-time migration progress (78.5%)
- Historical sync records
- Timeline analysis

âœ… **Quality Assurance**
- Identify complex code that needs review
- Track dependencies between entities
- Optional AI validation

âœ… **Team Collaboration**
- Shared dashboard for entire team
- Export reports for stakeholders
- Easy status checks

âœ… **Future-Proof**
- Database schema extensible
- Add custom tags and notes
- Plugin system for custom checks

---

## ğŸ”§ Advanced Configuration

### Custom Entity Filters

```yaml
entity_tracking:
  track_entities:
    - modules
    - classes
    - functions
    - methods
    - variables    # Enable variable tracking
    - imports      # Enable import tracking
  
  # Exclude patterns
  exclude_entities:
    - test_*       # Skip test functions
    - _private     # Skip private methods
```

### AI Validation Providers

```yaml
# OpenAI
ai_validation:
  provider: "openai"
  openai:
    model: "gpt-4"

# Anthropic Claude
ai_validation:
  provider: "anthropic"
  anthropic:
    model: "claude-3-sonnet"

# Local LLM
ai_validation:
  provider: "local"
  local:
    model_path: "/path/to/llama-model"
```

---

## ğŸ“š Summary

The Entity Tracking System gives you:

1. **ğŸ“Š Complete visibility** - Track every entity from both codebases
2. **ğŸ¨ Beautiful dashboard** - Visualize migration progress
3. **ğŸ” Smart queries** - Find entities by type, status, complexity
4. **âš™ï¸ Easy configuration** - YAML-based setup
5. **ğŸ¤– AI validation** - Optional quality assurance
6. **ğŸ”„ Dual-track ready** - Integrates with dual-track sync
7. **ğŸ“ˆ Progress tracking** - Real-time migration metrics

**Perfect for your Risk Engine parallel development scenario!** ğŸ¯

---

**Next Steps:**
1. Edit `migration_config.yaml` with your paths
2. Run `python migration_manager.py --config migration_config.yaml --scan`
3. Launch dashboard: `python migration_manager.py --config migration_config.yaml --dashboard`
4. Start migrating! ğŸš€
