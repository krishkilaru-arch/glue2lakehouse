# âœ… Answer to Your Question

## Question: 
> "Let's say if I migrated the code to Databricks and then I changed the code in one of the files in the git repo for glue... can I ask this framework to update only that particular file or files?"

## Answer: YES! âœ…

You can now update only specific files or automatically detect and update only what changed!

---

## ğŸš€ Three Ways to Do This

### 1. **Automatic Detection** (Recommended)

The framework automatically detects which files changed and updates only those:

```bash
cd /Users/analytics360/glue2lakehouse
source venv/bin/activate

# Detect what changed
python -m glue2lakehouse detect-changes \
    --input glue_source/ \
    --output databricks_target/

# Update only the changed files
python -m glue2lakehouse update \
    --input glue_source/ \
    --output databricks_target/
```

### 2. **Update Specific File(s)** (Most Direct)

Tell it exactly which file(s) to update:

```bash
# Update one file
python -m glue2lakehouse update \
    --input glue_source/ \
    --output databricks_target/ \
    --files src/readers.py

# Update multiple files
python -m glue2lakehouse update \
    --input glue_source/ \
    --output databricks_target/ \
    --files src/readers.py \
    --files src/writers.py \
    --files jobs/daily_etl.py
```

### 3. **Automated Script** (For Regular Syncs)

Use the included script:

```bash
./sync_changes.sh
```

---

## ğŸ“ Complete Example

### Your Scenario:

1. You already migrated: `glue_source/` â†’ `databricks_target/`
2. You changed `src/readers.py` in `glue_source/`
3. You want to update only that file in `databricks_target/`

### Solution:

```bash
cd /Users/analytics360/glue2lakehouse
source venv/bin/activate

# Option A: Let it detect automatically
python -m glue2lakehouse update \
    -i glue_source/ \
    -o databricks_target/

# Option B: Specify the file explicitly
python -m glue2lakehouse update \
    -i glue_source/ \
    -o databricks_target/ \
    -f src/readers.py
```

**Output:**
```
Update Summary:
  Updated: 1

Files Updated:
  âœ“ src/readers.py
```

---

## ğŸ¯ How It Works

### State Tracking

After initial migration, the framework creates `.migration_state.json` in `databricks_target/`:

```json
{
  "src/readers.py": {
    "hash": "abc123def456...",
    "last_updated": "2026-02-04T10:30:00"
  },
  "src/writers.py": {
    "hash": "def456abc123...",
    "last_updated": "2026-02-04T10:30:00"
  }
}
```

### Change Detection

When you run `detect-changes` or `update`, it:
1. âœ… Calculates hash of each file in `glue_source/`
2. âœ… Compares with stored hash in state file
3. âœ… Identifies which files changed
4. âœ… Re-migrates only changed files
5. âœ… Updates state file with new hashes

---

## ğŸ“š New Commands

### `detect-changes`
See what changed without updating:

```bash
python -m glue2lakehouse detect-changes \
    -i glue_source/ \
    -o databricks_target/
```

### `update`
Update changed files:

```bash
# All changed files
python -m glue2lakehouse update -i glue_source/ -o databricks_target/

# Specific file(s)
python -m glue2lakehouse update -i glue_source/ -o databricks_target/ -f path/to/file.py
```

---

## ğŸ’¡ Real-World Workflows

### Workflow 1: Daily Sync

```bash
# Morning routine
cd glue_source/
git pull origin main

cd ..
python -m glue2lakehouse update -i glue_source/ -o databricks_target/

cd databricks_target/
git add .
git commit -m "Daily sync from Glue"
git push
```

### Workflow 2: Hot Fix

```bash
# Urgent fix in Glue
cd glue_source/
git pull  # Get the fix

cd ..
# Sync just that one file
python -m glue2lakehouse update \
    -i glue_source/ \
    -o databricks_target/ \
    -f jobs/critical_job.py

cd databricks_target/
git add jobs/critical_job.py
git commit -m "HOTFIX: Sync from Glue"
git push
```

### Workflow 3: Automated Sync

```bash
# Use the included script
./sync_changes.sh

# Or set up a cron job:
# 0 */4 * * * cd /path/to/glue2lakehouse && ./sync_changes.sh
```

---

## ğŸ What You Got

### New Features Added:

1. **IncrementalMigrator** class - Smart change detection
2. **`detect-changes`** command - See what changed
3. **`update`** command - Update only changed files
4. **`sync_changes.sh`** script - Automated syncing
5. **State tracking** - Knows what was migrated when

### New Documentation:

1. **[INCREMENTAL_MIGRATION.md](INCREMENTAL_MIGRATION.md)** - Complete guide (500+ lines)
2. **[INCREMENTAL_QUICKSTART.md](INCREMENTAL_QUICKSTART.md)** - Quick reference
3. **sync_changes.sh** - Automated sync script

---

## âš¡ Quick Reference

```bash
# See what changed
python -m glue2lakehouse detect-changes -i glue_source/ -o databricks_target/

# Update all changes
python -m glue2lakehouse update -i glue_source/ -o databricks_target/

# Update one file
python -m glue2lakehouse update -i glue_source/ -o databricks_target/ -f src/readers.py

# Update multiple files
python -m glue2lakehouse update -i glue_source/ -o databricks_target/ \
    -f file1.py -f file2.py -f file3.py

# Automated
./sync_changes.sh
```

---

## âœ¨ Benefits

- âš¡ **Fast** - Only processes changed files
- ğŸ¯ **Precise** - Update exactly what you need
- ğŸ”„ **Automated** - Can auto-detect changes
- ğŸ“Š **Tracked** - State file remembers everything
- ğŸ› ï¸ **Flexible** - Manual or automatic mode
- ğŸš€ **Efficient** - Perfect for parallel codebases

---

## ğŸŠ Summary

**Your Question:** Can I update only specific files after initial migration?

**Answer:** YES! Three ways:
1. âœ… Automatic detection: `update` command
2. âœ… Manual selection: `update -f file.py`
3. âœ… Automated script: `./sync_changes.sh`

**Perfect for:**
- ğŸ”„ Maintaining parallel Glue/Databricks codebases
- ğŸ› ï¸ Quick fixes and updates
- ğŸš€ Iterative migration approach
- âš¡ Fast syncing without re-migrating everything

---

**Start using it now!** See [INCREMENTAL_QUICKSTART.md](INCREMENTAL_QUICKSTART.md) for examples. ğŸš€
